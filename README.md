# ğŸ“ ê³ ì „ë¬¸í•™ ì‚¬ê³ ìœ ë„ AI í”„ë¡œì íŠ¸

> **ëª©í‘œ**: ê³ ì „ë¬¸í•™ í•™ìŠµìš© ì‚¬ê³ ìœ ë„ ëŒ€í™” AI + ìë™ í‰ê°€ ì‹œìŠ¤í…œ  
> **ë¦¬ì†ŒìŠ¤**: GCP í¬ë ˆë”§ 500ë§Œì›, AI HUB ë°ì´í„°ì…‹, Gemini API

---

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
4. [ë°ì´í„° ì „ëµ](#ë°ì´í„°-ì „ëµ)
5. [í•µì‹¬ ëª¨ë“ˆ](#í•µì‹¬-ëª¨ë“ˆ)
6. [í‰ê°€ ì‹œìŠ¤í…œ](#í‰ê°€-ì‹œìŠ¤í…œ)
7. [ì½”ë“œ êµ¬ì¡°](#ì½”ë“œ-êµ¬ì¡°)
8. [êµ¬í˜„ ì½”ë“œ](#êµ¬í˜„-ì½”ë“œ)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ëª©í‘œ
1. **ì‚¬ê³ ìœ ë„ AI**: ê³ ì „ë¬¸í•™ìœ¼ë¡œ í•™ìŠµëœ ëŒ€í™”í˜• AI (Gemma 3 íŒŒì¸íŠœë‹)
2. **ì‚¬ê³ ë¡œê·¸ ìƒì„±**: í•™ìƒì˜ ì‚¬ê³  ê³¼ì •ì„ êµ¬ì¡°í™”í•˜ì—¬ ìë™ ê¸°ë¡
3. **ìë™ í‰ê°€ ì‹œìŠ¤í…œ**: 
   - Gemini ê¸°ë°˜ ì§ˆì  í‰ê°€ (ì¶”ë¡ ê¹Šì´, ë¹„íŒì ì‚¬ê³ , ë¬¸í•™ì ì´í•´)
   - ì–¸ì–´ ë¶„ì„ ê¸°ë°˜ ì •ëŸ‰ í‰ê°€ (ì–´íœ˜ë‹¤ì–‘ì„±, ê°œë…ì–´ì‚¬ìš©, ê°ì •í†¤ ë“±)
4. **í™•ì¥ ê°€ëŠ¥ì„±**: ë‹¤ë¥¸ ê³¼ëª© ì½”í¼ìŠ¤ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ëª¨ë“ˆí˜• êµ¬ì¡°

### í•µì‹¬ ì°¨ë³„ì 
**ê¸°ì¡´**: ë‹¨ìˆœ ì§ˆë¬¸-ë‹µë³€  
**ìš°ë¦¬**: ì‚¬ê³  ìœ ë„ â†’ ì‚¬ê³ ë¡œê·¸ ìƒì„± â†’ ì§ˆì +ì •ëŸ‰ í‰ê°€ â†’ ê°œì¸ ë§ì¶¤ í”¼ë“œë°±

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ì „ì²´ ì‹œìŠ¤í…œ í”Œë¡œìš°                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[í•™ìƒ ì§ˆë¬¸] 
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gemma 3 9B (Fine-tuned)                               â”‚
â”‚  - ê³ ì „ë¬¸í•™ 600ê°œ ë°ì´í„° í•™ìŠµ                           â”‚
â”‚  - LoRA íŒŒì¸íŠœë‹                                       â”‚
â”‚  - ì†Œí¬ë¼í‹± ëŒ€í™” íŒ¨í„´ ì ìš©                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‚¬ê³ ìœ ë„ ëŒ€í™” + ì‚¬ê³ ë¡œê·¸ ìƒì„±                          â”‚
â”‚  [ì‚¬ê³ ìœ ë„] ë‹¨ê³„ì  ì§ˆë¬¸ìœ¼ë¡œ í•™ìƒ ì‚¬ê³  ìœ ë„              â”‚
â”‚  [ì‚¬ê³ ë¡œê·¸] í•™ìƒ ì‚¬ê³  ê³¼ì • ìë™ ê¸°ë¡                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                         â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini Pro  â”‚      â”‚  ì–¸ì–´ ë¶„ì„    â”‚       â”‚  ìœ í•´í‘œí˜„ AI   â”‚
â”‚ ì§ˆì  í‰ê°€   â”‚      â”‚  ì •ëŸ‰ í‰ê°€    â”‚       â”‚  (AI HUB)      â”‚
â”‚             â”‚      â”‚              â”‚       â”‚                â”‚
â”‚ â€¢ ì¶”ë¡ ê¹Šì´  â”‚      â”‚ â€¢ ì–´íœ˜ë‹¤ì–‘ì„±  â”‚       â”‚ â€¢ ìš•ì„¤ ê°ì§€    â”‚
â”‚ â€¢ ë¹„íŒì ì‚¬ê³ â”‚      â”‚ â€¢ ê°œë…ì–´ì‚¬ìš©  â”‚       â”‚ â€¢ ë¶€ì ì ˆì–¸ì–´   â”‚
â”‚ â€¢ ë¬¸í•™ì´í•´  â”‚      â”‚ â€¢ ë¬¸ì¥ë³µì¡ë„  â”‚       â”‚                â”‚
â”‚             â”‚      â”‚ â€¢ ê°ì •í†¤     â”‚       â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   í†µí•© í‰ê°€       â”‚
                    â”‚   (ì§ˆì  70%      â”‚
                    â”‚    ì •ëŸ‰ 30%)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    [ê°œì¸ ë§ì¶¤ í”¼ë“œë°±]
                    [êµì‚¬ìš© ë¦¬í¬íŠ¸]


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ê¸°ìˆ  ì•„í‚¤í…ì²˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Layer   â”‚      â”‚ Model Layer  â”‚      â”‚ Evaluation      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AI HUB       â”‚â”€â”€â”€â”€â”€â†’â”‚ Gemma 3 9B   â”‚â”€â”€â”€â”€â”€â†’â”‚ â€¢ Gemini Pro    â”‚
â”‚ â€¢ ê³ ì „ë¬¸í•™600 â”‚      â”‚ + LoRA       â”‚      â”‚ â€¢ ì–¸ì–´ë¶„ì„ê¸°    â”‚
â”‚ â€¢ ì§€ë¬¸í˜•ë¬¸ì œ â”‚      â”‚ (4bit quant) â”‚      â”‚ â€¢ ìœ í•´í‘œí˜„AI    â”‚
â”‚ â€¢ ì£¼ì œë³„í‰ê°€ â”‚      â”‚              â”‚      â”‚                 â”‚
â”‚ â€¢ êµê³¼ë°ì´í„° â”‚      â”‚              â”‚      â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ GCP Vertex AI    â”‚
                   â”‚ â€¢ A100/L4 GPU    â”‚
                   â”‚ â€¢ Cloud Storage  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ ê¸°ìˆ 

| ë¶„ì•¼ | ê¸°ìˆ  | ìš©ë„ |
|------|------|------|
| **Base Model** | Gemma 3 (9B-it) | ì‚¬ê³ ìœ ë„ ëŒ€í™” ìƒì„± |
| **Evaluation** | Gemini Pro (1.5) | ì§ˆì  í‰ê°€ |
| **Fine-tuning** | LoRA/QLoRA | ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í•™ìŠµ |
| **Language Analysis** | KoNLPy + Custom | ì •ëŸ‰ì  ì–¸ì–´ ë¶„ì„ |
| **Harmful Content** | ìœ í•´í‘œí˜„ ê²€ì¶œ AI (AI HUB) | ìš•ì„¤/ë¶€ì ì ˆ ì–¸ì–´ ê°ì§€ |
| **Framework** | Transformers 4.38+ | ëª¨ë¸ ë¡œë”©/í•™ìŠµ |
| **Cloud** | GCP Vertex AI | í•™ìŠµ ì¸í”„ë¼ |

**ì™œ Gemma 3ì¸ê°€?**
- **ìµœì‹  ëª¨ë¸** (2025ë…„ 3ì›” ì¶œì‹œ, 11ê°œì›” ê²€ì¦)
- **ì„±ëŠ¥ í–¥ìƒ**: Gemma 2 ëŒ€ë¹„ ê°œì„ ëœ ì•„í‚¤í…ì²˜
- **ì¶©ë¶„í•œ ì•ˆì •ì„±**: íŒŒì¸íŠœë‹ ì‚¬ë¡€ í’ë¶€, ë²„ê·¸ í•´ê²°ë¨
- **GCP ì™„ë²½ ì§€ì›**: Vertex AI ìµœì í™”
- **êµìœ¡ ë¶„ì•¼ ì í•©**: ëŒ€í™”í˜• ìƒì„±ì— íŠ¹í™”

### íŒ¨í‚¤ì§€ ì˜ì¡´ì„±

```python
# requirements.txt

# í•µì‹¬ ëª¨ë¸
transformers==4.38.0
peft==0.9.0
accelerate==0.27.0
bitsandbytes==0.42.0
datasets==2.17.0
torch==2.1.0

# í‰ê°€ ì‹œìŠ¤í…œ
google-generativeai==0.4.0
google-cloud-aiplatform==1.40.0

# ì–¸ì–´ ë¶„ì„ (ê°œì„ )
konlpy==0.6.0
sentence-transformers==2.2.2      # ì˜ë¯¸ ìœ ì‚¬ë„ ë¶„ì„
scikit-learn==1.3.0               # ì½”ì‚¬ì¸ ìœ ì‚¬ë„

# ê¸°ë³¸
pandas==2.1.0
numpy==1.24.0
```

---

## ğŸ“Š ë°ì´í„° ì „ëµ

### ë³´ìœ  ë°ì´í„°ì…‹ (AI HUB)

| ë°ì´í„° | í¬ê¸° | ìš©ë„ | ìš°ì„ ìˆœìœ„ |
|--------|------|------|---------|
| ê³ ì „ë¬¸í•™ | 600ê°œ | ğŸ”´ **í•µì‹¬ í•™ìŠµ ë°ì´í„°** | 1 |
| êµ­ì–´ êµê³¼ ì§€ë¬¸í˜• ë¬¸ì œ | 1.26GB | ì§ˆë¬¸ íŒ¨í„´ í•™ìŠµ | 1 |
| ë…¼ìˆ í˜•/ì„œìˆ í˜• í‰ê°€ | 232MB | í‰ê°€ ë£¨ë¸Œë¦­ ì°¸ê³  | 1 |
| ìœ í•´í‘œí˜„ ê²€ì¶œ AI ëª¨ë¸ | 61MB | ìš•ì„¤/ë¶€ì ì ˆ ì–¸ì–´ ê°ì§€ | 1 |

### ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
[AI HUB ì›ë³¸ ë°ì´í„°]
- ê³ ì „ë¬¸í•™: 600ê°œ
- ì§€ë¬¸í˜• ë¬¸ì œ: 1.26GB
         â†“
[êµ¬ì¡° ë¶„ì„ & ì „ì²˜ë¦¬]
- ê³ ì „ë¬¸í•™ í…ìŠ¤íŠ¸ íŒŒì‹±
- ì§ˆë¬¸-ë‹µë³€ ìŒ ì¶”ì¶œ
         â†“
[ì†Œí¬ë¼í‹± ëŒ€í™” ë³€í™˜]
- ìˆ˜ë™ ì‘ì„±: 50ê°œ (ê³ í’ˆì§ˆ í…œí”Œë¦¿)
- ìë™ ë³€í™˜: 250ê°œ (GPT-4/Claude í™œìš©, ê³ ì „ë¬¸í•™ ì¤‘ì‹¬)
         â†“
[íƒœê·¸ ì¶”ê°€]
- [ì‚¬ê³ ìœ ë„] íƒœê·¸
- [ì‚¬ê³ ë¡œê·¸] íƒœê·¸
         â†“
[í’ˆì§ˆ ê²€ì¦ & í•„í„°ë§]
- ì €í’ˆì§ˆ ë°ì´í„° ì œê±°
- ì¼ê´€ì„± ê²€ì¦
         â†“
[ìµœì¢… í•™ìŠµ ë°ì´í„° 300ê°œ]
- Train: 240ê°œ (80%)
- Valid: 60ê°œ (20%)
```

### ë°ì´í„° í¬ë§·

```json
{
  "id": "classic_001",
  "source": "ì¶˜í–¥ì „",
  "instruction": "í•™ìƒì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ë©° ê³ ì „ë¬¸í•™ì„ ê°€ë¥´ì¹˜ì„¸ìš”. [ì‚¬ê³ ìœ ë„]ì™€ [ì‚¬ê³ ë¡œê·¸] íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
  "input": "í•™ìƒ: ì¶˜í–¥ì „ì—ì„œ ì´ëª½ë£¡ì´ ì‹ ë¶„ì„ ìˆ¨ê¸´ ì´ìœ ê°€ ë­”ê°€ìš”?",
  "output": "[ì‚¬ê³ ìœ ë„] ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ë¨¼ì € ì¡°ì„ ì‹œëŒ€ ì‹ ë¶„ì œë¥¼ ìƒê°í•´ë³¼ê¹Œìš”? ë§Œì•½ ì´ëª½ë£¡ì´ ì²˜ìŒë¶€í„° \"ì €ëŠ” ì–‘ë°˜ ë„ë ¨ë‹˜ì…ë‹ˆë‹¤\"ë¼ê³  ë°í˜”ë‹¤ë©´, ì¶˜í–¥ê³¼ì˜ ê´€ê³„ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì¡Œì„ê¹Œìš”? ì¶˜í–¥ì˜ ë°˜ì‘ì€ ì–´ë• ì„ê¹Œìš”?\n\n[ì‚¬ê³ ë¡œê·¸] í•™ìƒì´ ì‹ ë¶„ì œì™€ ì‚¬ë‘ì˜ ì§„ì •ì„±ì„ ì—°ê²°ì§€ì–´ ì‚¬ê³  ì‹œì‘. ì¡°ì„ ì‹œëŒ€ ì‚¬íšŒ êµ¬ì¡°ì— ëŒ€í•œ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ë¬¼ í–‰ë™ì˜ ë™ê¸°ë¥¼ ì¶”ë¡ í•˜ë ¤ëŠ” ì‹œë„ê°€ ë³´ì„. ì¶”ë¡  ê¹Šì´: ì¤‘ìƒ. ë§¥ë½ ì´í•´: ì–‘í˜¸."
}
```

---

## ğŸ”§ í•µì‹¬ ëª¨ë“ˆ

### 1. Gemma 3 íŒŒì¸íŠœë‹ ëª¨ë“ˆ
- **ì—­í• **: ê³ ì „ë¬¸í•™ ë°ì´í„°ë¡œ ì‚¬ê³ ìœ ë„ ëŒ€í™” í•™ìŠµ
- **ê¸°ìˆ **: LoRA (Low-Rank Adaptation) + 4-bit ì–‘ìí™”
- **í•™ìŠµ ì„¤ì •**:
  - Epochs: 3
  - Batch size: 4
  - Learning rate: 2e-4
  - ì˜ˆìƒ ì‹œê°„: 8-12ì‹œê°„ (A100 ê¸°ì¤€)

### 2. ì‚¬ê³ ìœ ë„ ì¶”ë¡  ì—”ì§„
- **ì—­í• **: í•™ìƒ ì§ˆë¬¸ â†’ ì‚¬ê³ ìœ ë„ ì‘ë‹µ + ì‚¬ê³ ë¡œê·¸ ìƒì„±
- **ì¶œë ¥**:
  - `[ì‚¬ê³ ìœ ë„]`: ë‹¨ê³„ì  ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ê³  ìœ ë„
  - `[ì‚¬ê³ ë¡œê·¸]`: í•™ìƒ ì‚¬ê³  ê³¼ì • ìë™ ê¸°ë¡

### 3. Gemini í‰ê°€ ì‹œìŠ¤í…œ (ì§ˆì )
- **3ì°¨ì› ë£¨ë¸Œë¦­**:
  1. **ì¶”ë¡  ê¹Šì´**: ë‹¤ì¸µì  ì‚¬ê³ , ë§¥ë½ í†µí•©
  2. **ë¹„íŒì  ì‚¬ê³ **: ë…ìì  í•´ì„, ë‹¤ì–‘í•œ ê´€ì 
  3. **ë¬¸í•™ì  ì´í•´**: ì‹œëŒ€/ë¬¸í™” ë§¥ë½, ì‘í’ˆ êµ¬ì¡°

### 4. ì–¸ì–´ ë¶„ì„ ëª¨ë“ˆ (ì •ëŸ‰)
- **6ê°€ì§€ ì§€í‘œ**:
  1. **ì–´íœ˜ ë‹¤ì–‘ì„±**: TTR (Type-Token Ratio)
  2. **í•µì‹¬ ê°œë…ì–´ ì‚¬ìš©**: ê³ ì „ë¬¸í•™ ê´€ë ¨ ìš©ì–´ ë¹ˆë„
  3. **ë¬¸ì¥ ë³µì¡ë„**: í‰ê·  ë¬¸ì¥ ê¸¸ì´ + ì ˆ ê°œìˆ˜
  4. **ë°˜ë³µ íŒ¨í„´**: ê³¼ë„í•œ ë°˜ë³µ í‘œí˜„ ê°ì§€
  5. **ê°ì • í†¤**: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¶„ì„
  6. **ìœ í•´í‘œí˜„ ê°ì§€**: AI HUB ëª¨ë¸ í™œìš© (ìš•ì„¤, ë¶€ì ì ˆ ì–¸ì–´)

### 5. í†µí•© í‰ê°€ ì‹œìŠ¤í…œ
- **ì§ˆì  í‰ê°€ (70%)**: Gemini ë£¨ë¸Œë¦­ ê¸°ë°˜
- **ì •ëŸ‰ í‰ê°€ (30%)**: ì–¸ì–´ ë¶„ì„ ì§€í‘œ
- **ìµœì¢… ì¶œë ¥**:
  - ì¢…í•© ì ìˆ˜ (A+~C+)
  - ê°œì¸ ë§ì¶¤ í”¼ë“œë°±
  - êµì‚¬ìš© ìƒì„¸ ë¦¬í¬íŠ¸

---

## ğŸ“ˆ í‰ê°€ ì‹œìŠ¤í…œ

### ì§ˆì  í‰ê°€ ë£¨ë¸Œë¦­ (Gemini)

#### 1. ì¶”ë¡  ê¹Šì´ (1-5ì )

| ì ìˆ˜ | ê¸°ì¤€ |
|------|------|
| 5ì  | ë‹¤ì¸µì  ì‚¬ê³ , ì—¬ëŸ¬ ìš”ì†Œ í†µí•©, í…ìŠ¤íŠ¸ ë§¥ë½ ê¹Šì´ ì´í•´ |
| 4ì  | ë…¼ë¦¬ì  ì¶”ë¡ , ë§¥ë½ê³¼ ë‚´ìš© ì—°ê²° |
| 3ì  | ê¸°ë³¸ì  ì¶”ë¡ , í‘œë©´ì  ë§¥ë½ ì´í•´ |
| 2ì  | ë‹¨í¸ì  ì´í•´, ë…¼ë¦¬ì  ì—°ê²° ë¶€ì¡± |
| 1ì  | í‘œë©´ì  ë°˜ì‘, ì¶”ë¡  ì—†ìŒ |

#### 2. ë¹„íŒì  ì‚¬ê³  (1-5ì )

| ì ìˆ˜ | ê¸°ì¤€ |
|------|------|
| 5ì  | ë…ìì  í•´ì„, ë‹¤ì–‘í•œ ê´€ì  ê³ ë ¤, í…ìŠ¤íŠ¸ ë¹„í‰ |
| 4ì  | ëŒ€ì•ˆì  í•´ì„ ì‹œë„, ì¼ë¶€ ê´€ì  ë‹¤ì–‘ì„± |
| 3ì  | ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€ |
| 2ì  | ë‹¨ìˆœ ì •ë³´ íšŒìƒ, í•´ì„ ì‹œë„ ë¯¸í¡ |
| 1ì  | ê´€ë ¨ ì—†ëŠ” ì‘ë‹µ ë˜ëŠ” ì˜¤í•´ |

#### 3. ë¬¸í•™ì  ì´í•´ (1-5ì )

| ì ìˆ˜ | ê¸°ì¤€ |
|------|------|
| 5ì  | ì‹œëŒ€ì /ë¬¸í™”ì  ë§¥ë½ í†µí•©, ì‘í’ˆ ì „ì²´ êµ¬ì¡° íŒŒì•… |
| 4ì  | ì‘í’ˆ êµ¬ì¡°ì™€ ì£¼ì œ ì´í•´ |
| 3ì  | ì¤„ê±°ë¦¬ì™€ ì£¼ìš” ì‚¬ê±´ ì´í•´ |
| 2ì  | ë¶€ë¶„ì  ì´í•´, ì˜¤í•´ ì¼ë¶€ í¬í•¨ |
| 1ì  | ì‘í’ˆ ë‚´ìš© ì˜¤í•´ |

---

### ì •ëŸ‰ í‰ê°€ ì§€í‘œ (ì–¸ì–´ ë¶„ì„)

#### 1. ì–´íœ˜ ë‹¤ì–‘ì„± (Vocabulary Diversity)

**ê°œì„ ëœ í‰ê°€ ë°©ë²•: ë‹¤ì¸µì  ë¶„ì„**

```python
ìµœì¢… ì ìˆ˜ = (
    ê¸°ë³¸_TTR * 0.3 +           # ê³ ìœ ë‹¨ì–´/ì „ì²´ë‹¨ì–´
    MTLD * 0.4 +               # í…ìŠ¤íŠ¸ ê¸¸ì´ ë³´ì •
    í’ˆì‚¬_ë‹¤ì–‘ì„± * 0.2 +        # ëª…ì‚¬/ë™ì‚¬/í˜•ìš©ì‚¬/ë¶€ì‚¬ ê· í˜•
    í•™ë¬¸ì _ì–´íœ˜ * 0.1          # í•œìì–´, ì „ë¬¸ìš©ì–´ ë¹„ìœ¨
)

ë“±ê¸‰:
- 0.75 ì´ìƒ: ìš°ìˆ˜ (í’ë¶€í•˜ê³  ì •êµí•œ ì–´íœ˜)
- 0.6-0.75: ì–‘í˜¸ (ì ì ˆí•œ ì–´íœ˜ ì‚¬ìš©)
- 0.4-0.6: ë³´í†µ (ê¸°ë³¸ì  ì–´íœ˜)
- 0.4 ë¯¸ë§Œ: ê°œì„ í•„ìš” (ì œí•œì  ì–´íœ˜)
```

**í•µì‹¬ ê¸°ìˆ **:
- **MTLD (Measure of Textual Lexical Diversity)**: í…ìŠ¤íŠ¸ ê¸¸ì´ì— ëœ ë¯¼ê°í•œ í•™ìˆ ì  ì§€í‘œ
- **í’ˆì‚¬ ì—”íŠ¸ë¡œí”¼**: ëª…ì‚¬/ë™ì‚¬/í˜•ìš©ì‚¬/ë¶€ì‚¬ì˜ ê· í˜•ë„ ì¸¡ì •
- **í•™ë¬¸ì  ì–´íœ˜ ë¹„ìœ¨**: í•œìì–´, 3ìŒì ˆ ì´ìƒ ëª…ì‚¬ ë“± ì¶”ìƒì  í‘œí˜„ë ¥

#### 2. í•µì‹¬ ê°œë…ì–´ ì‚¬ìš©

**ê°œì„ ëœ í‰ê°€ ë°©ë²•: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„**

```python
# ê³ ì •ëœ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ, ì˜ë¯¸ ê¸°ë°˜ ë§¤ì¹­
ê°œë…_ì¹´í…Œê³ ë¦¬ = {
    "ë¬¸í•™ì _ê¸°ë²•": ["ìƒì§•", "ì€ìœ ", "ë³µì„ ", "ë°˜ì „", "ê°ˆë“±êµ¬ì¡°"],
    "ì‚¬íšŒë¬¸í™”ì _ë§¥ë½": ["ì‹ ë¶„ì œ", "ì‹œëŒ€ì ë°°ê²½", "ê³„ê¸‰ê°ˆë“±", "ìœ êµì‚¬ìƒ"],
    "ì¸ê°„ê´€ê³„_ì‹¬ë¦¬": ["ì‚¬ë‘", "íš¨", "ì¶©", "ì ˆê°œ", "ìš•ë§", "ê°ˆë“±"],
    "ì£¼ì œ_ë©”ì‹œì§€": ["ì£¼ì œ", "êµí›ˆ", "í’ì", "ë¹„íŒ", "ê°€ì¹˜ê´€"]
}

# Sentence-BERTë¡œ ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚°
ìœ ì‚¬ë„ >= 0.6 â†’ ê°œë…ì–´ë¡œ ì¸ì •

ì˜ˆì‹œ:
- í•™ìƒ: "ê³„ê¸‰ì˜ ë²½" â†’ ë§¤ì¹­: "ì‹ ë¶„ì œ" (ìœ ì‚¬ë„ 0.78)
- í•™ìƒ: "ë§ˆìŒì˜ ê°ˆë“±" â†’ ë§¤ì¹­: "ì‹¬ë¦¬ì  ê°ˆë“±" (ìœ ì‚¬ë„ 0.82)

í‰ê°€:
- 5ê°œ ì´ìƒ + 3ê°œ ì¹´í…Œê³ ë¦¬: ìš°ìˆ˜
- 3-4ê°œ + 2ê°œ ì¹´í…Œê³ ë¦¬: ì–‘í˜¸
- 1-2ê°œ: ë³´í†µ
- 0ê°œ: ë¶€ì¡±
```

**í•µì‹¬ ê¸°ìˆ **:
- **Sentence-BERT (ko-sroberta)**: í•œêµ­ì–´ ë¬¸ì¥/ë‹¨ì–´ ì„ë² ë”©
- **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í‘œí˜„ ìë™ ì¸ì‹
- **ì‚¬ì „ ì—†ì´ë„ ì‘ë™**: í•™ìƒì´ ìì‹ ë§Œì˜ í‘œí˜„ì„ ì¨ë„ í‰ê°€ ê°€ëŠ¥

#### 3. ë¬¸ì¥ ë³µì¡ë„

```python
ë³µì¡ë„ = (í‰ê·  ë¬¸ì¥ ê¸¸ì´ / 10) + (í‰ê·  ì ˆ ê°œìˆ˜ * 2)

ë“±ê¸‰:
- 10 ì´ìƒ: ë³µì¡í•¨ (ì‹¬ì¸µì  ì‚¬ê³ )
- 6-10: ì ì ˆí•¨
- 6 ë¯¸ë§Œ: ë‹¨ìˆœí•¨
```

#### 4. ë°˜ë³µ íŒ¨í„´

```python
ê³¼ë„í•œ ë°˜ë³µ = ê°™ì€ ë‹¨ì–´/í‘œí˜„ 3íšŒ ì´ìƒ

í‰ê°€:
- ë°˜ë³µë¥  > 0.2: ì£¼ì˜ (ë‹¤ì–‘í•œ í‘œí˜„ ê¶Œì¥)
- ë°˜ë³µë¥  â‰¤ 0.2: ì–‘í˜¸
```

#### 5. ê°ì • í†¤

**ê°œì„ ëœ í‰ê°€ ë°©ë²•: ë§¥ë½ ê³ ë ¤ AI ëª¨ë¸**

```python
# ë‹¤ì¸µì  ê°ì • ë¶„ì„
1. ì „ì²´_ê°ì •: KcELECTRA ê°ì •ë¶„ì„ ëª¨ë¸
2. í•™ìŠµ_íƒœë„: íƒêµ¬ì  > ì ê·¹ì  > ê¸ì •ì  > ì¤‘ë¦½ì  > ì†Œê·¹ì 
3. ë§¥ë½_ê°ì •: ë¬¸ì¥ë³„ ë¶„ì„ í›„ í†µí•©

ìµœì¢…_í†¤ = (
    ì „ì²´_ê°ì • * 0.3 +
    í•™ìŠµ_íƒœë„ * 0.5 +    # í•™ìŠµ íƒœë„ë¥¼ ë” ì¤‘ì‹œ
    ë§¥ë½_ê°ì • * 0.2
)

5ë‹¨ê³„ í†¤:
- ë§¤ìš°ê¸ì •ì  (0.4~1.0): "í•™ìŠµ í¥ë¯¸ì™€ íƒêµ¬ ì˜ì§€ ë†’ìŒ"
- ê¸ì •ì  (0.1~0.4): "í•™ìŠµì— ì ê·¹ì "
- ì¤‘ë¦½ì  (-0.1~0.1): "ë³´í†µ ìˆ˜ì¤€, ë™ê¸°ë¶€ì—¬ í•„ìš”"
- ë¶€ì •ì  (-0.4~-0.1): "ë™ê¸° ì €í•˜, ì§€ì› í•„ìš”"
- ë§¤ìš°ë¶€ì •ì  (-1.0~-0.4): "ì¦‰ì‹œ ê°œì… í•„ìš”"

ì˜ˆì‹œ:
- "ì–´ë µì§€ë§Œ í¥ë¯¸ë¡­ë‹¤" â†’ ê¸ì •ì  (ë§¥ë½ ì´í•´)
- "ì´í•´ ì•ˆ ë¼. í•˜ì§€ë§Œ ë” ì•Œê³  ì‹¶ë‹¤" â†’ íƒêµ¬ì  (í•™ìŠµ ì˜ì§€)
```

**í•µì‹¬ ê¸°ìˆ **:
- **KcELECTRA**: í•œêµ­ì–´ ë§¥ë½ ì´í•´ ê°ì •ë¶„ì„ ëª¨ë¸
- **í•™ìŠµ íƒœë„ ë¶„ë¦¬**: ë‹¨ìˆœ ê°ì • vs í•™ìŠµ ì˜ì§€ êµ¬ë¶„
- **ë§¥ë½ ê³ ë ¤**: ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„ìœ¼ë¡œ ë‰˜ì•™ìŠ¤ íŒŒì•…

#### 6. ìœ í•´í‘œí˜„ ê°ì§€

```python
# AI HUB ìœ í•´í‘œí˜„ ê²€ì¶œ AI ëª¨ë¸ í™œìš©
ìœ í•´í‘œí˜„_ëª¨ë¸.detect(student_text)

ê²½ê³  ë ˆë²¨:
- ì•ˆì „: ìœ í•´í‘œí˜„ 0ê°œ
- ì£¼ì˜: 1-2ê°œ
- ê²½ê³ : 3ê°œ ì´ìƒ (êµì‚¬ ì•Œë¦¼)
```

---

### í†µí•© í‰ê°€ ì‚°ì¶œ

```python
# ì§ˆì  í‰ê°€ (70%)
ì§ˆì _ì ìˆ˜ = Gemini_í‰ê· ì ìˆ˜ * 0.7 * 20  # ìµœëŒ€ 70ì 

# ì •ëŸ‰ í‰ê°€ (30%)
ì–´íœ˜_ì ìˆ˜ = TTR * 10                    # ìµœëŒ€ 10ì 
ê°œë…_ì ìˆ˜ = min(ê°œë…ì–´_ì‚¬ìš© * 2, 10)     # ìµœëŒ€ 10ì 
ë³µì¡_ì ìˆ˜ = min(ë¬¸ì¥_ë³µì¡ë„, 10)         # ìµœëŒ€ 10ì 
ì •ëŸ‰_ì ìˆ˜ = ì–´íœ˜_ì ìˆ˜ + ê°œë…_ì ìˆ˜ + ë³µì¡_ì ìˆ˜

# ì´ì 
ì´ì  = ì§ˆì _ì ìˆ˜ + ì •ëŸ‰_ì ìˆ˜              # ìµœëŒ€ 100ì 

# ë“±ê¸‰
A+: 90ì  ì´ìƒ
A:  85-89ì 
B+: 80-84ì 
B:  75-79ì 
C+: 70-74ì 
```

---

### í‰ê°€ ê²°ê³¼ ì˜ˆì‹œ

```json
{
  "í•™ìƒ_ID": "student_001",
  "ì§ˆë¬¸": "ì¶˜í–¥ì „ì—ì„œ ì´ëª½ë£¡ì€ ì™œ ì‹ ë¶„ì„ ìˆ¨ê²¼ë‚˜ìš”?",
  
  "ì§ˆì _í‰ê°€": {
    "ì¶”ë¡ _ê¹Šì´": {"ì ìˆ˜": 4, "í”¼ë“œë°±": "ì‹ ë¶„ì œì™€ ì‚¬ë‘ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°"},
    "ë¹„íŒì _ì‚¬ê³ ": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "ê¸°ë³¸ì  ì¶”ë¡ , ëŒ€ì•ˆì  ê´€ì  í•„ìš”"},
    "ë¬¸í•™ì _ì´í•´": {"ì ìˆ˜": 4, "í”¼ë“œë°±": "ì‘í’ˆ ì£¼ì œì™€ ë°°ê²½ ì´í•´ ì–‘í˜¸"},
    "í‰ê· ": 3.67
  },
  
  "ì •ëŸ‰_ë¶„ì„": {
    "ì–´íœ˜_ë‹¤ì–‘ì„±": {"ì ìˆ˜": 0.68, "ë“±ê¸‰": "ì–‘í˜¸"},
    "í•µì‹¬_ê°œë…ì–´": {"ì‚¬ìš©íšŸìˆ˜": 5, "í‰ê°€": "ìš°ìˆ˜"},
    "ë¬¸ì¥_ë³µì¡ë„": {"ì ìˆ˜": 7.2, "ë“±ê¸‰": "ì ì ˆí•¨"},
    "ë°˜ë³µ_íŒ¨í„´": {"ë°˜ë³µë¥ ": 0.15, "í‰ê°€": "ì–‘í˜¸"},
    "ê°ì •_í†¤": {"ì ìˆ˜": 0.6, "í†¤": "ê¸ì •ì "},
    "ìœ í•´í‘œí˜„": {"ê°ì§€": 0, "ê²½ê³ ë ˆë²¨": "ì•ˆì „"}
  },
  
  "ì¢…í•©_ê²°ê³¼": {
    "ì§ˆì _ì ìˆ˜": 51.4,
    "ì •ëŸ‰_ì ìˆ˜": 23.8,
    "ì´ì ": 75.2,
    "ë“±ê¸‰": "B"
  },
  
  "ê°œì¸_í”¼ë“œë°±": [
    "âœ… ì‚¬ê³ ì˜ ê¹Šì´ê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤.",
    "âœ… ë‹¤ì–‘í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "âœ… í•µì‹¬ ê°œë…ì„ ì˜ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "ğŸ’¡ ë¹„íŒì  ê´€ì ì„ ë” ë°œì „ì‹œì¼œë³´ì„¸ìš”.",
    "ğŸ’¡ ë‹¤ì–‘í•œ í•´ì„ ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•´ë³´ì„¸ìš”."
  ]
}
```

---

## ğŸ“‚ ì½”ë“œ êµ¬ì¡°

```
classical-literature-ai/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml
â”‚   â”œâ”€â”€ evaluation_config.yaml
â”‚   â””â”€â”€ rubric.json
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # ì›ë³¸ AI HUB ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ classics/           # ê³ ì „ë¬¸í•™ 600ê°œ
â”‚   â”‚   â”œâ”€â”€ comprehension/      # ì§€ë¬¸í˜• ë¬¸ì œ 1.26GB
â”‚   â”‚   â””â”€â”€ evaluation/         # ë…¼ìˆ í˜•/ì„œìˆ í˜• í‰ê°€ 232MB
â”‚   â”œâ”€â”€ processed/              # ì „ì²˜ë¦¬ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”‚   â””â”€â”€ valid.jsonl
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ socratic_patterns.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessor.py     # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ converter.py        # ì†Œí¬ë¼í‹± ë³€í™˜
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Gemma íŒŒì¸íŠœë‹
â”‚   â”‚   â””â”€â”€ inferencer.py       # ì¶”ë¡  ì—”ì§„
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ gemini_evaluator.py # Gemini ì§ˆì  í‰ê°€
â”‚   â”‚   â””â”€â”€ language_analyzer.py # ì–¸ì–´ ë¶„ì„ ì •ëŸ‰ í‰ê°€
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ pipeline.py         # í†µí•© íŒŒì´í”„ë¼ì¸
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ gcp_utils.py
â”‚       â””â”€â”€ harmful_detector.py # ìœ í•´í‘œí˜„ AI ì—°ë™
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gemma_finetuned/        # í•™ìŠµëœ ëª¨ë¸
â”‚   â””â”€â”€ harmful_expression/     # ìœ í•´í‘œí˜„ AI ëª¨ë¸
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ thought_logs/
â”‚   â”œâ”€â”€ evaluations/
â”‚   â””â”€â”€ reports/
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train.py
    â”œâ”€â”€ evaluate.py
    â””â”€â”€ generate_report.py
```

---

## ğŸ’» êµ¬í˜„ ì½”ë“œ

### 1. ë°ì´í„° ì „ì²˜ë¦¬ (`src/data/preprocessor.py`)

```python
"""
AI HUB ë°ì´í„°ë¥¼ ì†Œí¬ë¼í‹± ëŒ€í™”ë¡œ ë³€í™˜
"""

import json
import openai
from typing import List, Dict

class SocraticConverter:
    def __init__(self, api_key: str):
        self.api_key = api_key
        openai.api_key = api_key
    
    def convert_to_socratic(
        self, 
        passage: str, 
        question: str, 
        answer: str
    ) -> Dict:
        """ì›ë³¸ Q&Aë¥¼ ì†Œí¬ë¼í‹± ëŒ€í™”ë¡œ ë³€í™˜"""
        
        prompt = f"""ë‹¤ìŒ ê³ ì „ë¬¸í•™ ì§ˆë¬¸ì„ ì†Œí¬ë¼í‹± ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

[ì›ë³¸ ì§€ë¬¸]
{passage}

[í•™ìƒ ì§ˆë¬¸]
{question}

[ëª¨ë²” ë‹µì•ˆ]
{answer}

[ë³€í™˜ ìš”êµ¬ì‚¬í•­]
1. [ì‚¬ê³ ìœ ë„] íƒœê·¸: í•™ìƒì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ëŠ” ë‹¨ê³„ì  ì§ˆë¬¸ (2-3ê°œ)
2. [ì‚¬ê³ ë¡œê·¸] íƒœê·¸: í•™ìƒì´ ê±°ì¹  ì‚¬ê³  ê³¼ì • ì˜ˆì¸¡ ë° ê¸°ë¡
3. ì§ì ‘ ë‹µì„ ì£¼ì§€ ë§ê³ , ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ë„ë¡ ìœ ë„

[ì¶œë ¥ í˜•ì‹]
[ì‚¬ê³ ìœ ë„] (ë‹¨ê³„ì  ì§ˆë¬¸)
[ì‚¬ê³ ë¡œê·¸] (ì˜ˆìƒ ì‚¬ê³  ê³¼ì •, ì¶”ë¡  ê¹Šì´/ë§¥ë½ ì´í•´ë„ í¬í•¨)
"""
        
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì†Œí¬ë¼í‹± ëŒ€í™”ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        converted_text = response.choices[0].message.content
        
        return {
            "instruction": "í•™ìƒì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ë©° ê³ ì „ë¬¸í•™ì„ ê°€ë¥´ì¹˜ì„¸ìš”. [ì‚¬ê³ ìœ ë„]ì™€ [ì‚¬ê³ ë¡œê·¸] íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
            "input": f"í•™ìƒ: {question}",
            "output": converted_text,
            "metadata": {
                "source": "AI_HUB",
                "passage": passage,
                "original_answer": answer
            }
        }
    
    def batch_convert(self, data_list: List[Dict], output_path: str):
        """ë°°ì¹˜ ë³€í™˜"""
        converted_data = []
        
        for i, item in enumerate(data_list):
            try:
                converted = self.convert_to_socratic(
                    passage=item['passage'],
                    question=item['question'],
                    answer=item['answer']
                )
                converted_data.append(converted)
                
                if (i + 1) % 50 == 0:
                    print(f"Progress: {i+1}/{len(data_list)}")
                    
            except Exception as e:
                print(f"Error at {i}: {e}")
                continue
        
        # JSONL ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in converted_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        return converted_data
```

---

### 2. Gemma íŒŒì¸íŠœë‹ (`src/model/trainer.py`)

```python
"""
Gemma 3 íŒŒì¸íŠœë‹ - LoRA ê¸°ë°˜
"""

import torch
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer,
    TrainingArguments,
    Trainer
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset

class GemmaTrainer:
    def __init__(self):
        self.model_name = "google/gemma-3-9b-it"
        
        self.lora_config = LoraConfig(
            r=16,
            lora_alpha=32,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
            lora_dropout=0.05,
            bias="none",
            task_type="CAUSAL_LM"
        )
    
    def load_model(self):
        """4-bit ì–‘ìí™” ëª¨ë¸ ë¡œë“œ"""
        
        tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        tokenizer.pad_token = tokenizer.eos_token
        
        model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            device_map="auto",
            torch_dtype=torch.bfloat16,
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4"
        )
        
        model = prepare_model_for_kbit_training(model)
        model = get_peft_model(model, self.lora_config)
        
        return model, tokenizer
    
    def prepare_dataset(self, data_path: str, tokenizer):
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        
        dataset = load_dataset('json', data_files=data_path)
        
        def format_and_tokenize(example):
            text = f"""{example['instruction']}

{example['input']}

{example['output']}"""
            
            tokens = tokenizer(
                text,
                truncation=True,
                max_length=1024,
                padding="max_length"
            )
            tokens["labels"] = tokens["input_ids"].copy()
            return tokens
        
        return dataset.map(
            format_and_tokenize,
            remove_columns=dataset["train"].column_names
        )["train"]
    
    def train(
        self, 
        train_dataset,
        output_dir: str = "models/gemma_finetuned",
        num_epochs: int = 3
    ):
        """í•™ìŠµ ì‹¤í–‰"""
        
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=num_epochs,
            per_device_train_batch_size=4,
            gradient_accumulation_steps=4,
            learning_rate=2e-4,
            fp16=True,
            logging_steps=10,
            save_steps=100,
            warmup_steps=100,
            optim="paged_adamw_8bit"
        )
        
        model, tokenizer = self.load_model()
        
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset
        )
        
        trainer.train()
        trainer.save_model(output_dir)
        tokenizer.save_pretrained(output_dir)
```

---

### 3. ì¶”ë¡  ì—”ì§„ (`src/model/inferencer.py`)

```python
"""
ì‚¬ê³ ìœ ë„ ì¶”ë¡  ì—”ì§„
"""

import re
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

class ThoughtInducer:
    def __init__(self, model_path: str):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.tokenizer = self.load_model(model_path)
    
    def load_model(self, model_path: str):
        """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ"""
        
        base_model = AutoModelForCausalLM.from_pretrained(
            "google/gemma-3-9b-it",
            device_map="auto",
            torch_dtype=torch.bfloat16,
            load_in_4bit=True
        )
        
        model = PeftModel.from_pretrained(base_model, model_path)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model.eval()
        
        return model, tokenizer
    
    def generate_response(
        self, 
        student_input: str,
        max_new_tokens: int = 256
    ) -> dict:
        """ì‚¬ê³ ìœ ë„ ì‘ë‹µ ìƒì„±"""
        
        prompt = f"""í•™ìƒì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ë©° ê³ ì „ë¬¸í•™ì„ ê°€ë¥´ì¹˜ì„¸ìš”. [ì‚¬ê³ ìœ ë„]ì™€ [ì‚¬ê³ ë¡œê·¸] íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

í•™ìƒ: {student_input}

AI: [ì‚¬ê³ ìœ ë„]"""
        
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=0.7,
                do_sample=True,
                top_p=0.9
            )
        
        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        ai_response = full_response.split("AI: ")[-1]
        
        induction = self._extract_tag(ai_response, "ì‚¬ê³ ìœ ë„")
        log = self._extract_tag(ai_response, "ì‚¬ê³ ë¡œê·¸")
        
        return {
            "induction": induction,
            "log": log,
            "full_response": ai_response
        }
    
    def _extract_tag(self, text: str, tag: str) -> str:
        """íƒœê·¸ ë‚´ìš© ì¶”ì¶œ"""
        pattern = rf"\[{tag}\](.*?)(?=\[|$)"
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1).strip() if match else ""
```

---

### 4. ì–¸ì–´ ë¶„ì„ ëª¨ë“ˆ (`src/evaluation/language_analyzer.py`)

```python
"""
ê°œì„ ëœ í•™ìƒ ì–¸ì–´ ì‚¬ìš© íŒ¨í„´ ë¶„ì„ (ì •ëŸ‰ í‰ê°€)
"""

from collections import Counter
from typing import Dict, List, Tuple
from konlpy.tag import Okt
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import numpy as np
import math

class ComprehensiveLanguageAnalyzer:
    """í†µí•© ì–¸ì–´ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, harmful_model_path: str = None):
        # ê¸°ë³¸ ë¶„ì„ê¸°
        self.okt = Okt()
        
        # ê°œì„ ëœ ë¶„ì„ê¸°ë“¤
        self.vocab_analyzer = ImprovedVocabularyAnalyzer()
        self.concept_analyzer = SemanticConceptAnalyzer()
        self.sentiment_analyzer = AdvancedSentimentAnalyzer()
        
        # ìœ í•´í‘œí˜„ AI ëª¨ë¸ (AI HUB)
        if harmful_model_path:
            self.harmful_detector = self._load_harmful(harmful_model_path)
    
    def analyze(self, student_text: str) -> Dict:
        """ì¢…í•© ë¶„ì„"""
        
        morphs = self.okt.morphs(student_text)
        sentences = self._split_sentences(student_text)
        
        return {
            # ê°œì„ ëœ ë¶„ì„
            "ì–´íœ˜_ë‹¤ì–‘ì„±": self.vocab_analyzer.calculate_diversity(student_text),
            "í•µì‹¬_ê°œë…ì–´": self.concept_analyzer.analyze_concepts(student_text),
            "ê°ì •_í†¤": self.sentiment_analyzer.analyze_sentiment(student_text),
            
            # ê¸°ì¡´ ë¶„ì„ (ìœ ì§€)
            "ë¬¸ì¥_ë³µì¡ë„": self._calc_complexity(sentences, morphs),
            "ë°˜ë³µ_íŒ¨í„´": self._analyze_repetition(morphs),
            "ìœ í•´í‘œí˜„": self._detect_harmful(student_text),
            
            # í†µê³„
            "í†µê³„": {
                "ì´_ë‹¨ì–´": len(morphs),
                "ê³ ìœ _ë‹¨ì–´": len(set(morphs)),
                "ë¬¸ì¥_ìˆ˜": len(sentences),
                "í‰ê· _ë¬¸ì¥_ê¸¸ì´": round(len(morphs) / len(sentences), 1) if sentences else 0
            }
        }
    
    def _calc_complexity(self, sentences: List[str], morphs: List[str]) -> Dict:
        """ë¬¸ì¥ ë³µì¡ë„ (ê¸°ì¡´ ìœ ì§€)"""
        if not sentences:
            return {"ì ìˆ˜": 0, "ë“±ê¸‰": "N/A"}
        
        avg_length = len(morphs) / len(sentences)
        avg_clauses = sum(s.count(',') + 1 for s in sentences) / len(sentences)
        score = (avg_length / 10) + (avg_clauses * 2)
        
        if score >= 10:
            grade = "ë³µì¡í•¨"
        elif score >= 6:
            grade = "ì ì ˆí•¨"
        else:
            grade = "ë‹¨ìˆœí•¨"
        
        return {"ì ìˆ˜": round(score, 2), "ë“±ê¸‰": grade}
    
    def _analyze_repetition(self, morphs: List[str]) -> Dict:
        """ë°˜ë³µ íŒ¨í„´ (ê¸°ì¡´ ìœ ì§€)"""
        freq = Counter(morphs)
        excessive = {w: c for w, c in freq.items() if c >= 3 and len(w) > 1}
        repetition_rate = sum(excessive.values()) / len(morphs) if morphs else 0
        
        return {
            "ê³¼ë„í•œ_ë°˜ë³µ": excessive,
            "ë°˜ë³µë¥ ": round(repetition_rate, 3),
            "í‰ê°€": "ì£¼ì˜" if repetition_rate > 0.2 else "ì–‘í˜¸"
        }
    
    def _detect_harmful(self, text: str) -> Dict:
        """ìœ í•´í‘œí˜„ ê°ì§€ (AI HUB ëª¨ë¸)"""
        if hasattr(self, 'harmful_detector'):
            result = self.harmful_detector.predict(text)
            detected_count = len(result.get('harmful_expressions', []))
        else:
            detected_count = 0
        
        if detected_count == 0:
            level = "ì•ˆì „"
        elif detected_count <= 2:
            level = "ì£¼ì˜"
        else:
            level = "ê²½ê³ "
        
        return {
            "ê°ì§€_ê°œìˆ˜": detected_count,
            "ê²½ê³ _ë ˆë²¨": level,
            "ì¡°ì¹˜": "êµì‚¬ ì•Œë¦¼ í•„ìš”" if level == "ê²½ê³ " else "ì •ìƒ"
        }
    
    def _split_sentences(self, text: str) -> List[str]:
        import re
        return [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
    
    def _load_harmful(self, path: str):
        """AI HUB ìœ í•´í‘œí˜„ AI ëª¨ë¸ ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ ì‹œ AI HUB ëª¨ë¸ ë¡œë”© ì½”ë“œ
        pass


# ============================================================
# ê°œì„ ëœ ë¶„ì„ê¸° 1: ì–´íœ˜ ë‹¤ì–‘ì„±
# ============================================================

class ImprovedVocabularyAnalyzer:
    """MTLD ê¸°ë°˜ ì–´íœ˜ ë‹¤ì–‘ì„± ë¶„ì„"""
    
    def __init__(self):
        self.okt = Okt()
    
    def calculate_diversity(self, text: str) -> Dict:
        """
        ë‹¤ì¸µì  ì–´íœ˜ ë‹¤ì–‘ì„± ë¶„ì„
        - MTLD (í…ìŠ¤íŠ¸ ê¸¸ì´ ë³´ì •)
        - í’ˆì‚¬ ë‹¤ì–‘ì„±
        - í•™ë¬¸ì  ì–´íœ˜
        """
        morphs = self.okt.morphs(text)
        
        if not morphs:
            return {"ì ìˆ˜": 0, "ë“±ê¸‰": "N/A", "í•´ì„": "í…ìŠ¤íŠ¸ ì—†ìŒ"}
        
        # 1. ê¸°ë³¸ TTR
        basic_ttr = len(set(morphs)) / len(morphs)
        
        # 2. MTLD
        mtld_score = self._calculate_mtld(morphs)
        
        # 3. í’ˆì‚¬ ë‹¤ì–‘ì„±
        pos_diversity = self._pos_diversity(text)
        
        # 4. í•™ë¬¸ì  ì–´íœ˜
        academic_score = self._academic_vocabulary(morphs)
        
        # ìµœì¢… ì ìˆ˜
        final_score = (
            basic_ttr * 0.3 +
            mtld_score * 0.4 +
            pos_diversity * 0.2 +
            academic_score * 0.1
        )
        
        return {
            "ì ìˆ˜": round(final_score, 3),
            "ë“±ê¸‰": self._grade(final_score),
            "ì„¸ë¶€": {
                "ê¸°ë³¸_TTR": round(basic_ttr, 3),
                "MTLD": round(mtld_score, 3),
                "í’ˆì‚¬_ë‹¤ì–‘ì„±": round(pos_diversity, 3),
                "í•™ë¬¸ì _ì–´íœ˜": round(academic_score, 3)
            },
            "í•´ì„": self._interpret(final_score)
        }
    
    def _calculate_mtld(self, morphs: List[str], threshold: float = 0.72) -> float:
        """MTLD ê³„ì‚° (í…ìŠ¤íŠ¸ ê¸¸ì´ ë³´ì •)"""
        if len(morphs) < 10:
            return len(set(morphs)) / len(morphs)
        
        factors = []
        start = 0
        
        for i in range(10, len(morphs)):
            segment = morphs[start:i]
            ttr = len(set(segment)) / len(segment)
            if ttr < threshold:
                factors.append(i - start)
                start = i
        
        if start < len(morphs):
            factors.append(len(morphs) - start)
        
        avg_factor = sum(factors) / len(factors) if factors else 10
        return min(avg_factor / 50, 1.0)
    
    def _pos_diversity(self, text: str) -> float:
        """í’ˆì‚¬ ë‹¤ì–‘ì„± (ì—”íŠ¸ë¡œí”¼)"""
        pos = self.okt.pos(text)
        pos_counts = {"Noun": 0, "Verb": 0, "Adjective": 0, "Adverb": 0}
        
        for word, tag in pos:
            if tag.startswith("N"):
                pos_counts["Noun"] += 1
            elif tag.startswith("V"):
                pos_counts["Verb"] += 1
            elif tag.startswith("Adj"):
                pos_counts["Adjective"] += 1
            elif tag.startswith("Adv"):
                pos_counts["Adverb"] += 1
        
        total = sum(pos_counts.values())
        if total == 0:
            return 0
        
        entropy = 0
        for count in pos_counts.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)
        
        return entropy / 2  # ì •ê·œí™”
    
    def _academic_vocabulary(self, morphs: List[str]) -> float:
        """í•™ë¬¸ì  ì–´íœ˜ ë¹„ìœ¨ (3ìŒì ˆ ì´ìƒ, í•œìì–´ ë“±)"""
        academic_count = sum(1 for m in morphs if len(m) >= 3)
        return academic_count / len(morphs) if morphs else 0
    
    def _grade(self, score: float) -> str:
        if score >= 0.75:
            return "ìš°ìˆ˜"
        elif score >= 0.6:
            return "ì–‘í˜¸"
        elif score >= 0.4:
            return "ë³´í†µ"
        else:
            return "ê°œì„ í•„ìš”"
    
    def _interpret(self, score: float) -> str:
        if score >= 0.75:
            return "í’ë¶€í•˜ê³  ì •êµí•œ ì–´íœ˜ ì‚¬ìš©. í•™ë¬¸ì  í‘œí˜„ë ¥ ìš°ìˆ˜."
        elif score >= 0.6:
            return "ì ì ˆí•œ ì–´íœ˜ ì‚¬ìš©. ë‹¤ì–‘ì„± ì–‘í˜¸."
        elif score >= 0.4:
            return "ê¸°ë³¸ì  ì–´íœ˜ ì‚¬ìš©. í‘œí˜„ë ¥ í–¥ìƒ í•„ìš”."
        else:
            return "ì œí•œì  ì–´íœ˜. ë‹¤ì–‘í•œ í‘œí˜„ ì—°ìŠµ ê¶Œì¥."


# ============================================================
# ê°œì„ ëœ ë¶„ì„ê¸° 2: í•µì‹¬ ê°œë…ì–´ (ì„ë² ë”© ê¸°ë°˜)
# ============================================================

class SemanticConceptAnalyzer:
    """ì˜ë¯¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê°œë…ì–´ ë¶„ì„"""
    
    def __init__(self):
        # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        self.okt = Okt()
        
        # í•µì‹¬ ê°œë… ì¹´í…Œê³ ë¦¬
        self.concept_categories = {
            "ë¬¸í•™ì _ê¸°ë²•": ["ìƒì§•", "ì€ìœ ", "ë³µì„ ", "ë°˜ì „", "ê°ˆë“±êµ¬ì¡°", "ì¸ë¬¼í˜•ìƒí™”"],
            "ì‚¬íšŒë¬¸í™”ì _ë§¥ë½": ["ì‹ ë¶„ì œ", "ì‹œëŒ€ì ë°°ê²½", "ê³„ê¸‰ê°ˆë“±", "ìœ êµì‚¬ìƒ", "ê°€ë¶€ì¥ì œ"],
            "ì¸ê°„ê´€ê³„_ì‹¬ë¦¬": ["ì‚¬ë‘", "íš¨", "ì¶©", "ì ˆê°œ", "ìš•ë§", "ê°ˆë“±", "í™”í•´", "í¬ìƒ"],
            "ì£¼ì œ_ë©”ì‹œì§€": ["ì£¼ì œ", "êµí›ˆ", "í’ì", "ë¹„íŒ", "ê°€ì¹˜ê´€", "ì´ìƒ"]
        }
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì„ë² ë”© ìƒì„±
        self.category_embeddings = {
            cat: self.model.encode(words)
            for cat, words in self.concept_categories.items()
        }
    
    def analyze_concepts(self, student_text: str) -> Dict:
        """ì˜ë¯¸ ê¸°ë°˜ ê°œë…ì–´ ë¶„ì„"""
        
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = self.okt.nouns(student_text)
        if not nouns:
            return self._empty_result()
        
        # í›„ë³´ ì„ë² ë”©
        candidates = list(set(nouns))
        candidate_embeddings = self.model.encode(candidates)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¹­
        category_matches = {}
        all_similarities = []
        threshold = 0.6
        
        for cat_name, cat_emb in self.category_embeddings.items():
            similarities = np.dot(candidate_embeddings, cat_emb.T)
            matches = []
            
            for i, cand in enumerate(candidates):
                max_sim = similarities[i].max()
                if max_sim >= threshold:
                    matched = self.concept_categories[cat_name][similarities[i].argmax()]
                    matches.append({
                        "í•™ìƒí‘œí˜„": cand,
                        "ë§¤ì¹­ê°œë…": matched,
                        "ìœ ì‚¬ë„": round(float(max_sim), 3)
                    })
                    all_similarities.append(max_sim)
            
            if matches:
                category_matches[cat_name] = matches
        
        total_matches = sum(len(m) for m in category_matches.values())
        avg_similarity = np.mean(all_similarities) if all_similarities else 0
        coverage = len(category_matches)
        
        return {
            "ì¹´í…Œê³ ë¦¬ë³„_ë§¤ì¹­": category_matches,
            "ì´_ê°œë…_ì‚¬ìš©": total_matches,
            "í‰ê· _ìœ ì‚¬ë„": round(float(avg_similarity), 3),
            "ì»¤ë²„ë¦¬ì§€": coverage,
            "í‰ê°€": self._evaluate(total_matches, coverage),
            "í•´ì„": self._interpret(total_matches, coverage)
        }
    
    def _evaluate(self, total: int, coverage: int) -> str:
        if total >= 5 and coverage >= 3:
            return "ìš°ìˆ˜"
        elif total >= 3 and coverage >= 2:
            return "ì–‘í˜¸"
        elif total >= 1:
            return "ë³´í†µ"
        else:
            return "ë¶€ì¡±"
    
    def _interpret(self, total: int, coverage: int) -> str:
        if total >= 5 and coverage >= 3:
            return "ë‹¤ì–‘í•œ ë¬¸í•™ì  ê°œë…ì„ ì ì ˆíˆ í™œìš©"
        elif total >= 3:
            return "í•µì‹¬ ê°œë…ì„ ë¶€ë¶„ì ìœ¼ë¡œ ì‚¬ìš©"
        else:
            return "ê°œë…ì  ìš©ì–´ ì‚¬ìš© ë¶€ì¡±. ë¬¸í•™ì  ê°œë… í™œìš© ê¶Œì¥"
    
    def _empty_result(self) -> Dict:
        return {
            "ì¹´í…Œê³ ë¦¬ë³„_ë§¤ì¹­": {},
            "ì´_ê°œë…_ì‚¬ìš©": 0,
            "í‰ê· _ìœ ì‚¬ë„": 0,
            "ì»¤ë²„ë¦¬ì§€": 0,
            "í‰ê°€": "ë¶€ì¡±",
            "í•´ì„": "ëª…ì‚¬ ë˜ëŠ” ê°œë…ì–´ ê°ì§€ë˜ì§€ ì•ŠìŒ"
        }


# ============================================================
# ê°œì„ ëœ ë¶„ì„ê¸° 3: ê°ì • í†¤ (ë§¥ë½ ê³ ë ¤ AI ëª¨ë¸)
# ============================================================

class AdvancedSentimentAnalyzer:
    """KcELECTRA ê¸°ë°˜ ê°ì • ë¶„ì„"""
    
    def __init__(self):
        # í•œêµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸
        try:
            self.sentiment_model = pipeline(
                "sentiment-analysis",
                model="beomi/KcELECTRA-base-v2022"
            )
        except:
            self.sentiment_model = None
        
        # í•™ìŠµ ê´€ë ¨ í‚¤ì›Œë“œ
        self.learning_positive = ["í¥ë¯¸ë¡­", "ì¬ë¯¸ìˆ", "ì´í•´í–ˆ", "ê³µê°", "ì¸ìƒì "]
        self.learning_negative = ["ì–´ë µ", "ì´í•´ì•ˆ", "ëª¨ë¥´ê² ", "í—·ê°ˆ", "ë³µì¡"]
        self.learning_constructive = ["ê¶ê¸ˆ", "ë”ì•Œê³ ì‹¶", "ìƒê°í•´ë³¼", "íƒêµ¬"]
    
    def analyze_sentiment(self, text: str) -> Dict:
        """ë‹¤ì¸µì  ê°ì • ë¶„ì„"""
        
        # 1. ì „ì²´ ê°ì • (AI ëª¨ë¸)
        if self.sentiment_model:
            try:
                result = self.sentiment_model(text)[0]
                overall = result['label']
                confidence = result['score']
            except:
                overall, confidence = "neutral", 0.5
        else:
            overall, confidence = "neutral", 0.5
        
        # 2. í•™ìŠµ íƒœë„
        learning_tone = self._analyze_learning_tone(text)
        
        # 3. ë§¥ë½ ê°ì •
        contextual = self._contextual_sentiment(text)
        
        # ìµœì¢… í†µí•©
        final_tone, final_score = self._integrate_sentiments(
            overall, learning_tone, contextual
        )
        
        return {
            "ì „ì²´_ê°ì •": overall,
            "ì‹ ë¢°ë„": round(confidence, 3),
            "í•™ìŠµ_íƒœë„": learning_tone,
            "ìµœì¢…_í†¤": final_tone,
            "ì ìˆ˜": round(final_score, 3),
            "í•´ì„": self._interpret_tone(final_tone, learning_tone)
        }
    
    def _analyze_learning_tone(self, text: str) -> str:
        """í•™ìŠµ íƒœë„ ë¶„ì„"""
        pos = sum(1 for w in self.learning_positive if w in text)
        neg = sum(1 for w in self.learning_negative if w in text)
        con = sum(1 for w in self.learning_constructive if w in text)
        
        if con >= 2:
            return "íƒêµ¬ì "
        elif pos >= neg + 2:
            return "ì ê·¹ì "
        elif pos > neg:
            return "ê¸ì •ì "
        elif neg > pos + 2:
            return "ì†Œê·¹ì "
        else:
            return "ì¤‘ë¦½ì "
    
    def _contextual_sentiment(self, text: str) -> Dict:
        """ë§¥ë½ ê³ ë ¤ ê°ì •"""
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        if not sentences:
            return {"í‰ê· _ê°ì •": 0}
        
        if not self.sentiment_model:
            return {"í‰ê· _ê°ì •": 0}
        
        sent_scores = []
        for sent in sentences:
            try:
                result = self.sentiment_model(sent)[0]
                label = 1 if result['label'].lower() == 'positive' else -1
                sent_scores.append(label * result['score'])
            except:
                sent_scores.append(0)
        
        return {"í‰ê· _ê°ì •": round(float(np.mean(sent_scores)), 3)}
    
    def _integrate_sentiments(
        self, overall: str, learning: str, contextual: Dict
    ) -> Tuple[str, float]:
        """í†µí•©"""
        overall_score = 0.5 if overall.lower() == 'positive' else -0.5
        learning_scores = {
            "íƒêµ¬ì ": 0.8, "ì ê·¹ì ": 0.6, "ê¸ì •ì ": 0.4,
            "ì¤‘ë¦½ì ": 0, "ì†Œê·¹ì ": -0.4
        }
        learning_score = learning_scores.get(learning, 0)
        contextual_score = contextual.get("í‰ê· _ê°ì •", 0)
        
        final_score = (
            overall_score * 0.3 +
            learning_score * 0.5 +
            contextual_score * 0.2
        )
        
        if final_score > 0.4:
            tone = "ë§¤ìš°ê¸ì •ì "
        elif final_score > 0.1:
            tone = "ê¸ì •ì "
        elif final_score > -0.1:
            tone = "ì¤‘ë¦½ì "
        elif final_score > -0.4:
            tone = "ë¶€ì •ì "
        else:
            tone = "ë§¤ìš°ë¶€ì •ì "
        
        return tone, final_score
    
    def _interpret_tone(self, tone: str, learning: str) -> str:
        if "ë§¤ìš°ê¸ì •" in tone and learning == "íƒêµ¬ì ":
            return "í•™ìŠµ í¥ë¯¸ì™€ íƒêµ¬ ì˜ì§€ ë†’ìŒ. ë§¤ìš° ìš°ìˆ˜í•œ í•™ìŠµ íƒœë„."
        elif "ê¸ì •" in tone:
            return "í•™ìŠµì— ì ê·¹ì . ê¸ì •ì  íƒœë„ ìœ ì§€."
        elif "ë¶€ì •" in tone:
            return "í•™ìŠµ ë™ê¸° ì €í•˜. ì§€ì› í•„ìš”."
        else:
            return "ë³´í†µ ìˆ˜ì¤€ì˜ í•™ìŠµ íƒœë„."
```

---

### 5. Gemini í‰ê°€ (`src/evaluation/gemini_evaluator.py`)

```python
"""
Gemini ê¸°ë°˜ ì§ˆì  í‰ê°€
"""

import json
import google.generativeai as genai
from typing import Dict

class GeminiEvaluator:
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        
        self.rubric = {
            "ì¶”ë¡ _ê¹Šì´": {
                "5": "ë‹¤ì¸µì  ì‚¬ê³ , í…ìŠ¤íŠ¸ ë§¥ë½ ê¹Šì´ ì´í•´",
                "4": "ë…¼ë¦¬ì  ì¶”ë¡ , ë§¥ë½ ì—°ê²°",
                "3": "ê¸°ë³¸ì  ì¶”ë¡ ",
                "2": "ë‹¨í¸ì  ì´í•´",
                "1": "í‘œë©´ì  ë°˜ì‘"
            },
            "ë¹„íŒì _ì‚¬ê³ ": {
                "5": "ë…ìì  í•´ì„, ë‹¤ì–‘í•œ ê´€ì ",
                "4": "ëŒ€ì•ˆì  í•´ì„ ì‹œë„",
                "3": "ì§ì ‘ì  ë‹µë³€",
                "2": "ë‹¨ìˆœ ì •ë³´ íšŒìƒ",
                "1": "ê´€ë ¨ ì—†ëŠ” ì‘ë‹µ"
            },
            "ë¬¸í•™ì _ì´í•´": {
                "5": "ì‹œëŒ€/ë¬¸í™” ë§¥ë½ í†µí•©",
                "4": "ì‘í’ˆ êµ¬ì¡° ì´í•´",
                "3": "ì¤„ê±°ë¦¬ ì´í•´",
                "2": "ë¶€ë¶„ì  ì´í•´",
                "1": "ì˜¤í•´"
            }
        }
    
    def evaluate(self, student_input: str, thought_log: str) -> Dict:
        """ì§ˆì  í‰ê°€"""
        
        prompt = f"""ê³ ì „ë¬¸í•™ êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ë¡œì„œ í•™ìƒì˜ ì‚¬ê³ ë¥¼ í‰ê°€í•˜ì„¸ìš”.

[í‰ê°€ ë£¨ë¸Œë¦­]
{json.dumps(self.rubric, ensure_ascii=False, indent=2)}

[í•™ìƒ ì§ˆë¬¸]
{student_input}

[ì‚¬ê³ ë¡œê·¸]
{thought_log}

[ì¶œë ¥ í˜•ì‹ - JSONë§Œ ì¶œë ¥]
{{
  "ì¶”ë¡ _ê¹Šì´": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ë¹„íŒì _ì‚¬ê³ ": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ë¬¸í•™ì _ì´í•´": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ì¢…í•©_í‰ê°€": "...",
  "ì´ì ": X,
  "í‰ê· ": X.XX
}}
"""
        
        response = self.model.generate_content(prompt)
        
        try:
            json_text = response.text
            if "```json" in json_text:
                json_text = json_text.split("```json")[1].split("```")[0]
            
            evaluation = json.loads(json_text.strip())
            
            if "ì´ì " not in evaluation:
                scores = [
                    evaluation["ì¶”ë¡ _ê¹Šì´"]["ì ìˆ˜"],
                    evaluation["ë¹„íŒì _ì‚¬ê³ "]["ì ìˆ˜"],
                    evaluation["ë¬¸í•™ì _ì´í•´"]["ì ìˆ˜"]
                ]
                evaluation["ì´ì "] = sum(scores)
                evaluation["í‰ê· "] = round(sum(scores) / 3, 2)
            
            return evaluation
            
        except:
            return self._fallback_eval()
    
    def _fallback_eval(self) -> Dict:
        return {
            "ì¶”ë¡ _ê¹Šì´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "í‰ê°€ ì˜¤ë¥˜"},
            "ë¹„íŒì _ì‚¬ê³ ": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "í‰ê°€ ì˜¤ë¥˜"},
            "ë¬¸í•™ì _ì´í•´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "í‰ê°€ ì˜¤ë¥˜"},
            "ì¢…í•©_í‰ê°€": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
            "ì´ì ": 9,
            "í‰ê· ": 3.0
        }
```

---

### 6. í†µí•© íŒŒì´í”„ë¼ì¸ (`src/integration/pipeline.py`)

```python
"""
ì „ì²´ ì‹œìŠ¤í…œ í†µí•©
"""

from src.model.inferencer import ThoughtInducer
from src.evaluation.gemini_evaluator import GeminiEvaluator
from src.evaluation.language_analyzer import LanguageAnalyzer

class IntegratedPipeline:
    def __init__(
        self, 
        model_path: str, 
        gemini_key: str,
        harmful_model_path: str = None
    ):
        self.thought_inducer = ThoughtInducer(model_path)
        self.gemini_eval = GeminiEvaluator(gemini_key)
        self.lang_analyzer = ComprehensiveLanguageAnalyzer(harmful_model_path)
    
    def process(self, student_input: str) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        # 1. ì‚¬ê³ ìœ ë„ ëŒ€í™” ìƒì„±
        response = self.thought_inducer.generate_response(student_input)
        
        # 2. ì§ˆì  í‰ê°€ (Gemini)
        qualitative = self.gemini_eval.evaluate(
            student_input,
            response['log']
        )
        
        # 3. ì •ëŸ‰ ë¶„ì„ (ì–¸ì–´)
        quantitative = self.lang_analyzer.analyze(student_input)
        
        # 4. í†µí•© í‰ê°€
        integrated = self._integrate_evaluation(qualitative, quantitative)
        
        return {
            "ì‚¬ê³ ìœ ë„_ì‘ë‹µ": response['induction'],
            "ì‚¬ê³ ë¡œê·¸": response['log'],
            "ì§ˆì _í‰ê°€": qualitative,
            "ì •ëŸ‰_ë¶„ì„": quantitative,
            "í†µí•©_í‰ê°€": integrated,
            "ê°œì¸_í”¼ë“œë°±": self._generate_feedback(qualitative, quantitative)
        }
    
    def _integrate_evaluation(self, qual: Dict, quan: Dict) -> Dict:
        """ì§ˆì  + ì •ëŸ‰ í†µí•©"""
        
        # ì§ˆì  70%
        qual_score = qual['í‰ê· '] * 0.7 * 20
        
        # ì •ëŸ‰ 30%
        vocab = quan['ì–´íœ˜_ë‹¤ì–‘ì„±']['ì ìˆ˜'] * 10
        concept = min(quan['í•µì‹¬_ê°œë…ì–´']['ì´_ì‚¬ìš©'] * 2, 10)
        complexity = min(quan['ë¬¸ì¥_ë³µì¡ë„']['ì ìˆ˜'], 10)
        quan_score = vocab + concept + complexity
        
        total = qual_score + quan_score
        
        if total >= 90:
            grade = "A+"
        elif total >= 85:
            grade = "A"
        elif total >= 80:
            grade = "B+"
        elif total >= 75:
            grade = "B"
        else:
            grade = "C+"
        
        return {
            "ì§ˆì _ì ìˆ˜": round(qual_score, 1),
            "ì •ëŸ‰_ì ìˆ˜": round(quan_score, 1),
            "ì´ì ": round(total, 1),
            "ë“±ê¸‰": grade
        }
    
    def _generate_feedback(self, qual: Dict, quan: Dict) -> List[str]:
        """ê°œì¸ ë§ì¶¤ í”¼ë“œë°±"""
        
        feedback = []
        
        # ê°•ì 
        if qual['í‰ê· '] >= 4:
            feedback.append("âœ… ì‚¬ê³ ì˜ ê¹Šì´ê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤.")
        if quan['ì–´íœ˜_ë‹¤ì–‘ì„±']['ì ìˆ˜'] >= 0.6:
            feedback.append("âœ… ë‹¤ì–‘í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        if quan['í•µì‹¬_ê°œë…ì–´']['ì´_ì‚¬ìš©'] >= 5:
            feedback.append("âœ… í•µì‹¬ ê°œë…ì„ ì˜ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ê°œì„ ì 
        if qual['ë¹„íŒì _ì‚¬ê³ ']['ì ìˆ˜'] < 3:
            feedback.append("ğŸ’¡ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ìƒê°í•´ë³´ì„¸ìš”.")
        if quan['í•µì‹¬_ê°œë…ì–´']['ì´_ì‚¬ìš©'] < 3:
            feedback.append("ğŸ’¡ í•µì‹¬ ê°œë…ì–´ë¥¼ ë” í™œìš©í•´ë³´ì„¸ìš”.")
        if quan['ë°˜ë³µ_íŒ¨í„´']['ë°˜ë³µë¥ '] > 0.2:
            feedback.append("ğŸ’¡ ë‹¤ì–‘í•œ í‘œí˜„ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
        
        # ê²½ê³ 
        if quan['ìœ í•´í‘œí˜„']['ê²½ê³ _ë ˆë²¨'] != "ì•ˆì „":
            feedback.append("âš ï¸ ê¸ì •ì ì¸ ì–¸ì–´ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return feedback


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    pipeline = IntegratedPipeline(
        model_path="models/gemma_finetuned",
        gemini_key="YOUR_KEY",
        harmful_model_path="models/harmful_expression"
    )
    
    result = pipeline.process("ì¶˜í–¥ì „ì—ì„œ ì´ëª½ë£¡ì€ ì™œ ì‹ ë¶„ì„ ìˆ¨ê²¼ë‚˜ìš”?")
    
    print("=" * 60)
    print("ì‚¬ê³ ìœ ë„:", result['ì‚¬ê³ ìœ ë„_ì‘ë‹µ'])
    print("=" * 60)
    print("í‰ê°€ ê²°ê³¼:", result['í†µí•©_í‰ê°€'])
    print("=" * 60)
    print("í”¼ë“œë°±:")
    for fb in result['ê°œì¸_í”¼ë“œë°±']:
        print(f"  {fb}")
```

---

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

### ì„±ê³µì„ ìœ„í•œ 5ê°€ì§€ ì›ì¹™

1. **ë°ì´í„° í’ˆì§ˆ ìµœìš°ì„ **
   - 50ê°œ ê³ í’ˆì§ˆ ìƒ˜í”Œ ìˆ˜ë™ ì‘ì„±
   - ìë™ ë³€í™˜ í›„ ë°˜ë“œì‹œ ê²€ì¦

2. **ëª¨ë“ˆí˜• êµ¬ì¡°**
   - ê° ëª¨ë“ˆ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
   - í†µí•© ì „ ê°œë³„ ê²€ì¦

3. **í‰ê°€ ì‹œìŠ¤í…œ ê· í˜•**
   - ì§ˆì  70% + ì •ëŸ‰ 30%
   - ìœ í•´í‘œí˜„ì€ ë³„ë„ ì²˜ë¦¬

4. **í™•ì¥ì„± ê³ ë ¤**
   - ë‹¤ë¥¸ ì½”í¼ìŠ¤ë¡œ í™•ì¥ ê°€ëŠ¥
   - í‰ê°€ ë£¨ë¸Œë¦­ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥

5. **ì‹¤ì‹œê°„ í”¼ë“œë°±**
   - ì¦‰ê°ì ì¸ í‰ê°€ ë° í”¼ë“œë°±
   - êµì‚¬ìš© ìƒì„¸ ë¦¬í¬íŠ¸ ì œê³µ

---

## ğŸ”„ í™•ì¥ì„± (êµìˆ˜ë‹˜ ê°•ì¡° ì‚¬í•­)

### ì™œ ê³ ì „ë¬¸í•™ë§Œ ì‚¬ìš©í•˜ëŠ”ê°€?

**âœ… ì§‘ì¤‘ì„ í†µí•œ ê¹Šì´**
- 129GB ë²”ìš© ë°ì´í„°ë³´ë‹¤ 600ê°œ ê³ í’ˆì§ˆ ê³ ì „ë¬¸í•™ ë°ì´í„°ê°€ ë” íš¨ê³¼ì 
- ë„ë©”ì¸ íŠ¹í™” â†’ ì‚¬ê³ ìœ ë„ í’ˆì§ˆ ê·¹ëŒ€í™”
- íŒŒì¸íŠœë‹ ì‹œê°„ ìµœì í™” (8-12ì‹œê°„)

**âœ… í™•ì¥ì„±ì€ êµ¬ì¡°ë¡œ ì¦ëª…**

```python
# ë‹¤ë¥¸ ê³¼ëª© ì ìš© ì˜ˆì‹œ

# 1. ìˆ˜í•™ ë¬¸ì œ í’€ì´
math_data = load_dataset("math_problems")
math_model = GemmaTrainer().train(math_data)
# â†’ ê°™ì€ [ì‚¬ê³ ìœ ë„] + [ì‚¬ê³ ë¡œê·¸] ì‹œìŠ¤í…œ ì ìš©

# 2. ê³¼í•™ ì‹¤í—˜ ì„¤ê³„
science_data = load_dataset("science_experiments")
science_model = GemmaTrainer().train(science_data)
# â†’ ë™ì¼í•œ í‰ê°€ ì‹œìŠ¤í…œ (ì§ˆì  + ì •ëŸ‰)

# 3. ì—­ì‚¬ ì‚¬ê±´ ë¶„ì„
history_data = load_dataset("historical_events")
history_model = GemmaTrainer().train(history_data)
# â†’ ë£¨ë¸Œë¦­ë§Œ ì¡°ì •í•˜ë©´ ë°”ë¡œ ì ìš©
```

**âœ… ì‹¤ì œ í™•ì¥ ì‹œì—° ê³„íš**
- ë°œí‘œ ì‹œ: ìˆ˜í•™ ë¬¸ì œ 1-2ê°œë¡œ ì‹œìŠ¤í…œ ë²”ìš©ì„± ì¦ëª…
- ë°ëª¨: ì½”í¼ìŠ¤ êµì²´ë§Œìœ¼ë¡œ ì¦‰ì‹œ ì‘ë™í•˜ëŠ” ëª¨ìŠµ ë³´ì—¬ì¤Œ

**âœ… 129GB ë°ì´í„°ë¥¼ ì•ˆ ì“°ëŠ” ì´ìœ **
1. **ì´ˆì  ë¶„ì‚°**: ê³ ì „ë¬¸í•™ íŠ¹í™” ëª¨ë¸ vs ë²”ìš© ëª¨ë¸ â†’ ì „ìê°€ ìš°ìˆ˜
2. **ë¹„íš¨ìœ¨**: í•™ìŠµ ì‹œê°„ í­ì¦ (ìˆ˜ì¼ ~ ìˆ˜ì£¼)
3. **ë¶ˆí•„ìš”**: í™•ì¥ì„±ì€ ì•„í‚¤í…ì²˜ë¡œ ì…ì¦ ê°€ëŠ¥

â†’ **"ì ì€ ë°ì´í„°ë¡œ ë†’ì€ í’ˆì§ˆ"ì´ í•µì‹¬ ì „ëµ**

---

## ğŸ“Š ì˜ˆìƒ ì„±ê³¼

### ì •ëŸ‰ì  ì§€í‘œ
- **íŒŒì¸íŠœë‹ ì„±ê³µë¥ **: 95%+
- **í‰ê°€ ì •í™•ë„**: 85%+
- **ì‘ë‹µ ì‹œê°„**: í‰ê·  2-3ì´ˆ
- **ì‚¬ê³ ë¡œê·¸ ìƒì„±ë¥ **: 90%+

### ì •ì„±ì  ì„±ê³¼
- í•™ìƒ ì‚¬ê³ ë ¥ í–¥ìƒ ë„êµ¬
- êµì‚¬ í‰ê°€ ë¶€ë‹´ ê²½ê°
- ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ê°€ëŠ¥
- ë‹¤ê³¼ëª© í™•ì¥ ê°€ëŠ¥ì„± ì…ì¦

---

**ìµœì¢… ì •ë¦¬: ì´ ë¬¸ì„œë¡œ ë°”ë¡œ ê°œë°œ ì‹œì‘ ê°€ëŠ¥! ğŸš€**
